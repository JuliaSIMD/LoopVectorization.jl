<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Matrix Multiplication · LoopVectorization.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="LoopVectorization.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">LoopVectorization.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../getting_started/">Getting Started</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../multithreading/">Multithreading</a></li><li class="is-active"><a class="tocitem" href>Matrix Multiplication</a></li><li><a class="tocitem" href="../array_interface/">Array Interface</a></li><li><a class="tocitem" href="../matrix_vector_ops/">Matrix-Vector Operations</a></li><li><a class="tocitem" href="../dot_product/">Dot Products</a></li><li><a class="tocitem" href="../datetime_arrays/">Composite Types: DateTime Arrays</a></li><li><a class="tocitem" href="../special_functions/">Special Functions</a></li><li><a class="tocitem" href="../sum_of_squared_error/">Sum of squared error</a></li><li><a class="tocitem" href="../filtering/">Image Filtering</a></li></ul></li><li><a class="tocitem" href="../../vectorized_convenience_functions/">Vectorized Convenience Functions</a></li><li><a class="tocitem" href="../../future_work/">Future Work</a></li><li><a class="tocitem" href="../../api/">API reference</a></li><li><span class="tocitem">Developer Documentation</span><ul><li><a class="tocitem" href="../../devdocs/overview/">Developer Overview</a></li><li><a class="tocitem" href="../../devdocs/loopset_structure/">LoopSet Structure</a></li><li><a class="tocitem" href="../../devdocs/constructing_loopsets/">Constructing LoopSets</a></li><li><a class="tocitem" href="../../devdocs/evaluating_loops/">Determining the strategy for evaluating loops</a></li><li><a class="tocitem" href="../../devdocs/lowering/">Lowering</a></li><li><a class="tocitem" href="../../devdocs/reference/">Internals reference</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Matrix Multiplication</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Matrix Multiplication</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaSIMD/LoopVectorization.jl/blob/main/docs/src/examples/matrix_multiplication.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Matrix-Multiplication"><a class="docs-heading-anchor" href="#Matrix-Multiplication">Matrix Multiplication</a><a id="Matrix-Multiplication-1"></a><a class="docs-heading-anchor-permalink" href="#Matrix-Multiplication" title="Permalink"></a></h1><p>One of the friendliest problems for vectorization is matrix multiplication. Given <code>M × K</code> matrix <code>𝐀</code>, and <code>K × N</code> matrix <code>𝐁</code>, multiplying them is like performing <code>M * N</code> dot products of length <code>K</code>. We need <code>M*K + K*N + M*N</code> total memory, but <code>M*K*N</code> multiplications and additions, so there&#39;s a lot more arithmetic we can do relative to the memory needed.</p><p>LoopVectorization currently doesn&#39;t do any memory-modeling or memory-based optimizations, so it will still run into problems as the size of matrices increases. But at smaller sizes, it&#39;s capable of achieving a healthy percent of potential GFLOPS. We can write a single function:</p><pre><code class="language-julia hljs">function A_mul_B!(C, A, B)
    @turbo for n ∈ indices((C,B), 2), m ∈ indices((C,A), 1)
        Cmn = zero(eltype(C))
        for k ∈ indices((A,B), (2,1))
            Cmn += A[m,k] * B[k,n]
        end
        C[m,n] = Cmn
    end
end</code></pre><p>and this can handle all transposed/not-tranposed permutations. LoopVectorization will change loop orders and strategy as appropriate based on the types of the input matrices. For each of the others, I wrote separate functions to handle each case.  Letting all three matrices be square and <code>Size</code> x <code>Size</code>, we attain the following benchmark results:</p><p><img src="https://raw.githubusercontent.com/JuliaSIMD/LoopVectorization.jl/docsassets/docs/src/assets/bench_AmulB_v2.svg" alt="AmulB"/> This is classic GEMM, <code>𝐂 = 𝐀 * 𝐁</code>. GFortran&#39;s intrinsic <code>matmul</code> function does fairly well. But all the compilers are well behind LoopVectorization here, which falls behind MKL&#39;s <code>gemm</code> beyond 70x70 or so. The problem imposed by alignment is also striking: performance is much higher when the sizes are integer multiplies of 8. Padding arrays so that each column is aligned regardless of the number of rows can thus be very profitable. <a href="https://github.com/JuliaSIMD/PaddedMatrices.jl">PaddedMatrices.jl</a> offers just such arrays in Julia. I believe that is also what the <a href="https://software.intel.com/en-us/fortran-compiler-developer-guide-and-reference-pad-qpad">-pad</a> compiler flag does when using Intel&#39;s compilers.</p><p><img src="https://github.com/JuliaSIMD/LoopVectorization.jl/raw/docsassets/docs/src/assets/bench_AmulBt_v2.svg" alt="AmulBt"/> The optimal pattern for <code>𝐂 = 𝐀 * 𝐁ᵀ</code> is almost identical to that for <code>𝐂 = 𝐀 * 𝐁</code>. Yet, gfortran&#39;s <code>matmul</code> intrinsic stumbles, surprisingly doing much worse than gfortran + loops, and almost certainly worse than allocating memory for <code>𝐁ᵀ</code> and creating the explicit copy.</p><p>ifort did equally well whethor or not <code>𝐁</code> was transposed, while LoopVectorization&#39;s performance degraded slightly faster as a function of size in the transposed case, because strides between memory accesses are larger when <code>𝐁</code> is transposed. But it still performed best of all the compiled loops over this size range, losing out to MKL and eventually OpenBLAS. icc interestingly does better when it is transposed.</p><p>GEMM is easiest when the matrix <code>𝐀</code> is not tranposed (assuming column-major memory layouts), because then you can sum up columns of <code>𝐀</code> to store into <code>𝐂</code>. If <code>𝐀</code> were transposed, then we cannot efficiently load contiguous elements from <code>𝐀</code> that can best stored directly in <code>𝐂</code>. So for <code>𝐂 = 𝐀ᵀ * 𝐁</code>, contiguous vectors along the <code>k</code>-loop have to be reduced, adding some overhead. <img src="https://github.com/JuliaSIMD/LoopVectorization.jl/raw/docsassets/docs/src/assets/bench_AtmulB_v2.svg" alt="AtmulB"/> Packing is critical for performance here. LoopVectorization does not pack, therefore it is well behind MKL and OpenBLAS, which do. Eigen packs, but is poorly optimized for this CPU architecture.</p><p>When both <code>𝐀</code> and <code>𝐁</code> are transposed, we now have <code>𝐂 = 𝐀ᵀ * 𝐁ᵀ = (𝐁 * 𝐀)ᵀ</code>. <img src="https://github.com/JuliaSIMD/LoopVectorization.jl/raw/docsassets/docs/src/assets/bench_AtmulBt_v2.svg" alt="AtmulBt"/> Julia, Clang, and gfortran all struggled to vectorize this, because none of the matrices share a contiguous access: <code>M</code> for <code>𝐂</code>, <code>K</code> for <code>𝐀ᵀ</code>, and <code>N</code> for <code>𝐁ᵀ</code>. However, LoopVectorization and all the specialized matrix multiplication functions managed to do about as well as normal; transposing while storing the results takes negligible amounts of time relative to the matrix multiplication itself. The ifort-loop version also did fairly well.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../multithreading/">« Multithreading</a><a class="docs-footer-nextpage" href="../array_interface/">Array Interface »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Thursday 6 April 2023 20:07">Thursday 6 April 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
